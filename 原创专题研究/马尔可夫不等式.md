如果 $X$ 是一个非负的随机变量，那么 $P(X\ge a)$ 的上界是什么？

定义一个指示函数：
$$
I_{X\ge a}=\begin{cases}
1&x\ge a\\
0&x<a
\end{cases}
$$
显然，$E(I_{X\ge a})=P(X\ge a)$

发现 $X\ge aI_{X\ge a}$，这是因为，当 $X\ge a$ 时，$I_{X\ge a}=1$，自然也满足 $X\ge aI_{X\ge a}$，而当 $X<a$ 时，$I_{X\ge a}=0$，而 $X>0$，因此该不等式也满足

由于 $X,aI_{X\ge a}$ 都是非负的，因此有：
$$
E(X)\ge E(aI_{X\ge a})=aE(I_{X\ge a})=aP(X\ge a)
$$
因此：
$$
P(X\ge a)\le\frac{E(X)}a
$$
这就是**马尔可夫不等式**

 以此为基础推导切比雪夫不等式：

对于任意随机变量 $X$，它具有数学期望 $\mu$，方差 $\sigma^2$，那么，对于 $\forall \varepsilon>0$，根据马尔可夫不等式，直接有：
$$
P[(X-\mu)^2\ge\varepsilon^2]=P(|X-\mu|\ge\varepsilon)\le\frac{E[(X-\mu)^2]}{\varepsilon^2}=\frac{\sigma^2}{\varepsilon^2}
$$
切比雪夫不等式的另一种形式也可以利用同样的方法推导：
$$
P[(X-\mu)^2\ge\sigma^2\varepsilon^2]=P(|X-\mu|\ge\sigma\varepsilon)\le
\frac{E[(X-\mu)^2]}{\sigma^2\varepsilon^2}=\frac{1}{\varepsilon^2}
$$


推导辛钦大数定理：
$$
\forall\varepsilon>0,\lim_{n\to\infty} P\left\{
    \left|
        \frac1n\sum_{k=1}^nX_k-\mu
    \right|\ge\varepsilon
\right\}=0
$$
其中，$X_k,k=1,2,\cdots$ 是相互独立且服从同一分布的随机变量，$E(X_k)=\mu,D(X_k)=\sigma^2$

显然：
$$
E\left(\cfrac1n\sum_{k=1}^nX_k\right)=\mu
$$
根据切比雪夫不等式，直接有：
$$
P\left\{
    \left|
        \frac1n\sum_{k=1}^nX_k-\mu
    \right|\ge\varepsilon
\right\}\le
\frac{1}{\varepsilon^2}Var(\frac{1}{n}\sum_{k=1}^nX_k)=\frac{1}{\varepsilon^2n^2}Var(\sum_{k=1}^nX_k)
$$
由于 $X_k$ 相互独立，根据方差的性质：
$$
\forall i,j,Var(X_i+X_j)=Var(X_i)+Var(X_j)+Cov(X_i,X_k)=Var(X_i)+Var(X_j)=2\sigma^2
$$
因此：
$$
P\left\{
    \left|
        \frac1n\sum_{k=1}^nX_k-\mu
    \right|\ge\varepsilon
\right\}\le\frac{1}{\varepsilon^2n^2}Var(\sum_{k=1}^nX_k)=\frac{\sigma^2}{n\varepsilon^2}
$$
显然，$n\to\infty$ 时，$\le$ 右边 $\to 0$，因此：
$$
\forall\varepsilon>0,\lim_{n\to\infty} P\left\{
    \left|
        \frac1n\sum_{k=1}^nX_k-\mu
    \right|\ge\varepsilon
\right\}=0
$$
